# YOLO(You Only Look Once)

## Ques
1. Abstract: A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities for those boxes.

## Abstract

**MAP**: å¹³å‡ç²¾åº¦

## I. Instruction

> Current detection systems repurpose classifiers to perform detection. To detect an object, these systems take a classifier for that object and evaluate it at various locations and scales in a test image. Systems like deformable parts models (DPM) use a sliding window approach where the classifier is run at evenly spaced locations over the entire image [10].

### 1.1 ä¹‹å‰çš„æ£€æµ‹ç³»ç»Ÿæ˜¯å¦‚ä½•è¿›è¡Œç›®æ ‡æ£€æµ‹çš„ï¼Ÿ
- classifierï¼šåˆ©ç”¨åˆ†ç±»ç½‘ç»œ
- æ ¸å¿ƒæ€æƒ³ï¼šæ£€æµ‹ â‰ˆ â€œå±€éƒ¨åˆ†ç±»â€
  - æ—§æ–¹æ³•çš„åŸºæœ¬å‡è®¾æ˜¯ï¼šå¦‚æžœä¸€ä¸ªç›®æ ‡å‡ºçŽ°åœ¨å›¾åƒä¸­ï¼Œé‚£ä¹ˆå®ƒä¸€å®š**å®Œæ•´åœ°è½åœ¨æŸä¸ªâ€œå±€éƒ¨åŒºåŸŸâ€é‡Œ**
  - äºŽæ˜¯æ£€æµ‹è¢«è½¬åŒ–ä¸ºï¼šå¯¹å›¾åƒçš„**å¾ˆå¤šå­åŒºåŸŸåšåˆ†ç±»ï¼Œçœ‹å“ªäº›åŒºåŸŸâ€œåƒç›®æ ‡â€**
  - æ–¹æ³•å°±æ˜¯ï¼šæ”¹å˜å°ºåº¦+æ”¹å˜ä½ç½®ï¼Œç¬›å¡å°”ç§¯
  - ä½†æ˜¯æ˜¾è€Œæ˜“è§ï¼Œ**è®¡ç®—é‡çˆ†ç‚¸**
- DPä¹Ÿæ˜¯ï¼Œ**æ»‘çª—+å±€éƒ¨åˆ†ç±»/æ‰“åˆ†**

### 1.2. R-CNN æ˜¯æ€Žä¹ˆåšçš„ï¼Ÿ
- Step1. Region Proposalï¼ˆå€™é€‰åŒºåŸŸç”Ÿæˆï¼‰
  - R-CNN ä¸ç›´æŽ¥æ»‘çª—ï¼Œè€Œæ˜¯å…ˆç”¨ï¼šSelective Search æ¥ç”Ÿæˆå¤§çº¦ 2000 ä¸ªå€™é€‰æ¡†ï¼ˆregion proposalsï¼‰ï¼Œè¿™ä¸€æ­¥æ˜¯ä¼ ç»ŸCVç®—æ³•

- Step2. å¯¹æ¯ä¸ª proposal åšâ€œåˆ†ç±»â€
  - åˆ†ç±»å™¨åœ¨å±€éƒ¨åŒºåŸŸä¸Šè¿è¡Œï¼Œå› æ­¤**R-CNN ä»ç„¶æ˜¯ classifier-based detection**

- Step3. Bounding Box Regressionï¼ˆä½ç½®å¾®è°ƒï¼‰
  1. R-CNN å‘çŽ°ä¸€ä¸ªé—®é¢˜ï¼šproposal çš„æ¡†ï¼šå¤§è‡´å¯¹ï¼Œä½†ä¸å¤Ÿç²¾ç¡®ã€‚
  2. æ‰€ä»¥ï¼šå¯¹æ¯ä¸ª proposalå†è®­ç»ƒä¸€ä¸ª **å›žå½’å™¨**ï¼ŒåŽ»å¾®è°ƒ (x, y, w, h)
  3. è¿™ä¸€æ­¥ **æ˜¯å•ç‹¬è®­ç»ƒçš„çº¿æ€§å›žå½’å™¨**

- Step4. Post-processingï¼ˆåŽå¤„ç†ï¼‰
  After classification, post-processing is used to refine the bounding boxes, eliminate duplicate detections, and rescore the boxes based on other objects in the scene [13]
  åŒ…æ‹¬ï¼š
    - **Non-Maximum Suppression (NMS)**ï¼šåŽ»æŽ‰é‡å åº¦é«˜çš„é‡å¤æ£€æµ‹
    - å¯èƒ½è¿˜åŒ…æ‹¬ï¼š
      * åˆ†æ•°é‡æ ‡å®š
      * ç±»åˆ«é—´ä¸Šä¸‹æ–‡è°ƒæ•´
  
- é—®é¢˜ï¼š
  1. **å¤šé˜¶æ®µï¼Œå½¼æ­¤å‰²è£‚ï¼Œæ¯ä¸€ä¸ªéƒ½æ˜¯ç‹¬ç«‹ç»„ä»¶**
     1. Selective Searchï¼ˆä¸å¯å­¦ä¹ ï¼‰
     2. CNN åˆ†ç±»ï¼ˆå•ç‹¬è®­ç»ƒï¼‰
     3. SVMï¼ˆå¦ä¸€ä¸ªè®­ç»ƒè¿‡ç¨‹ï¼‰
     4. Bounding box regressionï¼ˆå†ä¸€ä¸ªæ¨¡åž‹ï¼‰
     5. NMSï¼ˆè§„åˆ™ï¼‰
  2. **æ— æ³•ç«¯åˆ°ç«¯è®­ç»ƒ**
    æ— æ³•åšåˆ°ï¼š
    > â€œæˆ‘æœ€åŽæ£€æµ‹æ•ˆæžœä¸å¥½ â†’
    > ç›´æŽ¥åå‘ä¼ æ’­åˆ°æœ€å‰é¢åŽ»æ”¹ç‰¹å¾â€
    å› ä¸ºï¼šproposal ä¸æ˜¯ç½‘ç»œäº§ç”Ÿçš„ã€åŽå¤„ç†æ˜¯æ‰‹å·¥è§„åˆ™
  3. **é€Ÿåº¦æ…¢**

R-CNN æœ¬è´¨ä¸Šè¿˜æ˜¯ classifier è¿‡ç¨‹ï¼Œåªæ˜¯æ»‘çª—ä¸ªæ•°å‡å°‘äº†ï¼Œè¿˜æ˜¯æœ‰å¤šæ¬¡â€œçœ‹â€è¿™å¼ å›¾ã€‚ä½†æ˜¯YOLOè§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå«åšï¼šYou Only Look Once.


### 1.3. YOLO çš„ä¼˜åŠ¿ä¸ŽåŠ£åŠ¿
#### ä¼˜åŠ¿
- é€Ÿåº¦å¿«
- çœ‹æ•´å¼ å›¾ç‰‡ï¼ŒèƒŒæ™¯è¯†åˆ«çš„é”™è¯¯è¾ƒå°‘
- å¯ä»¥å­¦åˆ°ç‰©ä½“çš„æ³›åŒ–ç‰¹å¾

#### åŠ£åŠ¿
YOLO still lags behind state-of-the-art detection systems in accuracy. While it can quickly identify objects in images it struggles to precisely localize some objects, especially small ones. We examine these tradeoffs further in our experiments
å®šä½çš„å‡†ç¡®æ€§ä¸é«˜ï¼Œè™½ç„¶èƒ½å¤Ÿå¿«é€Ÿè¯†åˆ«å›¾åƒä¸­çš„ç‰©ä½“


## II. Network Design

### 2.1 grid cellâ€”â€”ä¸­å¿ƒç‚¹å½’å±žåŽŸåˆ™
Our system divides the input image into an S Ã— S grid. If the center of an object falls into a grid cell, that grid cell is responsible for detecting that object.
> æˆ‘ä»¬çš„ç³»ç»Ÿå°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸ºSÃ—Sçš„ç½‘æ ¼ï¼ˆgridï¼‰ã€‚è‹¥æŸä¸ªç‰©ä½“çš„ä¸­å¿ƒè½å…¥æŸä¸ªç½‘æ ¼å•å…ƒï¼ˆgrid cellï¼‰ï¼Œåˆ™è¯¥ç½‘æ ¼å•å…ƒè´Ÿè´£æ£€æµ‹è¯¥ç‰©ä½“ã€‚

1. grid cell çš„åˆ’åˆ†ä¸Ž GT æ¡†çš„å¤§å°ã€ä½ç½®æ— å…³ï¼Œåªå’Œè¾“å…¥åˆ†è¾¨çŽ‡æœ‰å…³ã€‚ä¾‹å¦‚è¾“å…¥å›¾ç‰‡æ˜¯448Ã—448ï¼Œæˆ‘ä»¬é€‰æ‹©S=7ï¼ˆ7è¡Œ7åˆ—çš„ç½‘æ ¼åˆ’åˆ†ï¼‰ï¼Œé‚£ä¹ˆæ¯ä¸€ä¸ªç½‘æ ¼çš„åƒç´ å°ºå¯¸å°±æ˜¯64Ã—64
2. é™å®šä¸€ä¸ª GT æ¡†ç”±ä¸€ä¸ª grid cell è´Ÿè´£ï¼Œ**ä¸€ä¸ªgrid cellæœ€å¤šè´Ÿè´£ä¸€ä¸ª GT æ¡†**
3. grid cell ä¸Ž GT æ¡†çš„å¤§å°æ²¡æœ‰å›ºå®šå…³ç³»
   1. å¯¹äºŽå¤§ GT æ¡†ï¼Œå¯èƒ½æ¨ªè·¨å¤šä¸ª grid cellï¼Œé‚£ä¹ˆå°±ç”± GT æ¡†çš„ä¸­å¿ƒç‚¹æ‰€åœ¨çš„ grid cell è´Ÿè´£
   2. å¯¹äºŽå° GT æ¡†ï¼Œå°ºå¯¸ç›¸è¿‘ï¼Œå°±ç”±è¯¥ grid cell è´Ÿè´£
   3. å¯¹äºŽæžå°ã€å¯†é›†çš„ GT æ¡†ï¼Œ**å¤šä¸ª GT æ¡†å¯èƒ½è½åœ¨åŒä¸€ä¸ªgrid cellå†…**ï¼Œè¿™ç§æƒ…å†µä¸‹æ— æ³•å¤„ç†



### 2.2 grid cell, predictor and bounding box
Each grid cell predicts B bounding boxes and confidence scores for those boxes. These confidence scores reflect how confident the model is that the box contains an object and also how accurate it thinks the box is that it predicts. Formally we define confidence as $Pr(\text{Object}) * IOU^{\text{truth}}_{\text{pred}}$. If no object exists in that cell, the confidence scores should be zero. Otherwise we want the confidence score to equal the intersection over union (IOU) between the predicted box and the ground truth

#### 2.2.1 å…ˆç†è§£ä»€ä¹ˆæ˜¯confidence
\[
\text{confidence}=\underbrace{Pr(\text{Object})}_{\text{æœ‰æ²¡æœ‰ç‰©ä½“}}
\times
\underbrace{IOU^{truth}_{pred}}_{\text{æ¡†å¾—å‡†ä¸å‡†}}
\]

**Example**


1ï¸âƒ£ æƒ…å†µ Aï¼šæœ‰ç‰©ä½“ï¼Œä½†æ¡†å¾ˆçƒ‚

* é¢„æµ‹æ¡†ï¼š

  * çš„ç¡®è¦†ç›–äº†ä¸€ä¸ªçœŸå®žç‰©ä½“
  * ä½†ä½ç½®åç§»å¾ˆå¤§ã€å°ºå¯¸å¾ˆä¸å‡†

è¿™æ—¶ï¼š

* Pr(Object) â‰ˆ 1
* IOU â‰ˆ 0.2

ðŸ‘‰ confidence â‰ˆ 0.2

**è¯­ä¹‰è§£é‡Š**ï¼š

> â€œè¿™é‡Œç¡®å®žæœ‰ç‰©ä½“ï¼Œä½†æˆ‘æ¡†å¾—ä¸å¤ªè¡Œâ€

2ï¸âƒ£ æƒ…å†µ Bï¼šæ¡†å¾ˆæ¼‚äº®ï¼Œä½†ç›®æ ‡æ ¹æœ¬ä¸å­˜åœ¨

* é¢„æµ‹æ¡†ï¼š

  * çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªâ€œå¾ˆåˆç†â€çš„çŸ©å½¢
  * ä½†è¿™ä¸ªåŒºåŸŸ**åŽ‹æ ¹æ²¡æœ‰çœŸå®žç‰©ä½“**

è¿™æ—¶ï¼š

* Pr(Object) = 0
* IOUï¼ˆæ²¡æœ‰å®šä¹‰ / è§†ä¸º 0ï¼‰

ðŸ‘‰ confidence = 0

**è¯­ä¹‰è§£é‡Š**ï¼š

> â€œå³ä½¿è¿™ä¸ªæ¡†å½¢çŠ¶å†å¥½ï¼Œåªè¦æ²¡æœ‰ç‰©ä½“ï¼Œå°±ä¸€ç¥¨å¦å†³â€

3ï¸âƒ£ æƒ…å†µ Cï¼šæ—¢æœ‰ç‰©ä½“ï¼Œåˆæ¡†å¾—å¾ˆå‡†ï¼ˆç†æƒ³æƒ…å†µï¼‰

* Pr(Object) â‰ˆ 1
* IOU â‰ˆ 1

ðŸ‘‰ confidence â‰ˆ 1


4ï¸âƒ£ æƒ…å†µ Dï¼šèƒŒæ™¯åŒºåŸŸä¹±æ¡†

* Pr(Object) â‰ˆ 0
* IOU â‰ˆ 0

ðŸ‘‰ confidence â‰ˆ 0

**ç¬¦å·å®šä¹‰**

1ï¸âƒ£ Pr(Object)

* è¡¨ç¤ºï¼š

  > **å½“å‰è¿™ä¸ª bounding box å¯¹åº”çš„ä½ç½®ï¼Œæ˜¯å¦å­˜åœ¨ä¸€ä¸ªçœŸå®žç›®æ ‡**

åœ¨ YOLO v1 ä¸­ï¼š

* å¦‚æžœè¯¥ grid cell è´Ÿè´£æŸä¸ª GT boxï¼š

  * Pr(Object) = 1
* å¦åˆ™ï¼š

  * Pr(Object) = 0

âš ï¸ æ³¨æ„ï¼š
è¿™ä¸æ˜¯æ¦‚çŽ‡æ„ä¹‰ä¸Šçš„ soft labelï¼Œè€Œæ˜¯**è®­ç»ƒç›®æ ‡çš„å®šä¹‰**ã€‚


2ï¸âƒ£ $\text{IOU}^{truth}_{pred}$

\[
\text{IOU} = \frac{\text{Area of Intersection}}{\text{Area of Union}}
\]

* è¡¡é‡é¢„æµ‹æ¡†å’ŒçœŸå®žæ¡†çš„é‡åˆç¨‹åº¦
* âˆˆ [0, 1]

---

#### 2.2.2 grid cell ä¸Ž predictor ä¸Ž bounding box
1. ä¸€ä¸ªgrid cell åŒ…å«$B$ä¸ªpredictorï¼Œæˆ–è€…è¯´é¢„æµ‹$B$ä¸ªbounding boxï¼ŒB ä¸ª bounding box æ²¡æœ‰å›ºå®šå½¢çŠ¶å’Œä½ç½®$(x,y,w,h)$ï¼Œè¿™äº›å‚æ•°å®Œå…¨æ˜¯ç”±ç½‘ç»œé€šè¿‡**å›žå½’**å­¦ä¹ å‡ºæ¥
2. grid cell åªè´Ÿè´£é¢„æµ‹ï¼Œä¸é™åˆ¶ bounding box çš„ç©ºé—´èŒƒå›´ã€‚bounding box å¯ä»¥è·¨è¶Šä»»æ„å¤šä¸ª grid cellï¼Œä½†åœ¨ YOLO v1 ä¸­ï¼Œä¸€ä¸ªç‰©ä½“æ°¸è¿œåªç”±å…¶ä¸­å¿ƒç‚¹æ‰€åœ¨çš„é‚£ä¸ª grid cell è´Ÿè´£é¢„æµ‹ã€‚æ‰€ä»¥è¿™å°±æœ‰ä¸ªé—®é¢˜ï¼š
  - å°ç‰©ä½“ï¼šå¾ˆå®¹æ˜“**å¤šä¸ªä¸­å¿ƒç‚¹è½åŒä¸€ä¸ª cell â†’ å†²çª**
  - å¤§ç‰©ä½“ï¼šåªç”±ä¸€ä¸ª cell é¢„æµ‹ â†’ **å®šä½åŽ‹åŠ›æžå¤§**
3. æ¯ä¸ª predictor çš„ confidence å®šä¹‰ä¸­çš„ Object æŒ‡çš„æ˜¯â€œ**æ˜¯å¦å­˜åœ¨ä¸€ä¸ªç”±å½“å‰ grid cell è´Ÿè´£çš„çœŸå®žç‰©ä½“**â€ã€‚å¹¶ä¸”ï¼š
  - å¦‚æžœå½“å‰ grid cell æ²¡æœ‰è¢«åˆ†é… GT boxï¼Œé‚£åˆ«çŽ©äº†ï¼Œå…¨éƒ¨ predictor çš„ Pr éƒ½æ˜¯0
  - å¦‚æžœå½“å‰ grid cell è¢«åˆ†é…äº† GT boxï¼Œé‚£ä¹ˆï¼š
    1. åªæœ‰ IOU æœ€å¤§çš„é‚£ä¸ª box predictorï¼šPr(Object) = 1
    2. å…¶ä½™ B-1 ä¸ª box predictor: Pr(Object) = 0

**é‡è¦ç†è§£ï¼šB-1ä¸ª Pr=0 çš„è¯¦ç»†è§£é‡Šä»¥åŠæ„ä¹‰**
> åœ¨â€œå½“å‰è¿™ä¸ª cell è¢«åˆ†é…åˆ°ä¸€ä¸ª GT ç‰©ä½“â€çš„å‰æä¸‹ï¼Œ
è¯¥ cell å†…çš„ B ä¸ª box predictor éƒ½â€œå°è¯•(attempt)â€åŽ»é¢„æµ‹è¿™ä¸ª GTï¼Œä½†åœ¨**æ¯ä¸€æ¬¡å‰å‘**ä¸­ï¼Œåªæœ‰ IOU æœ€å¤§çš„é‚£ä¸ª predictor ä¼šè¢«é€‰ä¸ºâ€œè´Ÿè´£è¯¥ GTâ€çš„ predictor **å¹¶æŽ¥æ”¶å®Œæ•´ç›‘ç£ä¿¡å·**ã€‚åœ¨ä¸åŒæ ·æœ¬ã€ä¸åŒè®­ç»ƒé˜¶æ®µï¼Œè¿™ä¸ªâ€œèµ¢å®¶â€å¯èƒ½ä¼šå˜åŒ–ã€‚
> ðŸ‘‰ â€œå°è¯•ï¼ˆattemptï¼‰â€è€Œä¸æ˜¯â€œéƒ½åœ¨é¢„æµ‹â€
> åªæœ‰ winner predictorå›žå½’åæ ‡ï¼Œå…¶ä»– predictoråœ¨è¿™ä¸€è½®ä¸­è¢«å½“ä½œèƒŒæ™¯

**ç–‘æƒ‘1ï¼šæ¯ä¸ª cell çš„ B ä¸ª predictor æ˜¯ä¸æ˜¯åªä¼šé¢„æµ‹å½“å‰ cell å¯¹åº”çš„ GTï¼Ÿ**
> æ˜¯çš„ï¼Œåœ¨ YOLO v1 ä¸­ï¼Œä¸€ä¸ª cell çš„ B ä¸ª predictor åªå¯èƒ½å¯¹â€œè¿™ä¸ª cell è¢«åˆ†é…çš„ GTâ€è´Ÿè´£ï¼Œç»ä¸ä¼šè·¨ cell é¢„æµ‹å…¶ä»– GTã€‚

**ç–‘æƒ‘2ï¼šä¸€ä¸ª SÃ—S ç½‘æ ¼ï¼Œæ˜¯ä¸æ˜¯æœ‰ SÃ—SÃ—B ä¸ª predictorï¼Ÿ**
> æ˜¯çš„ï¼Œä¸¥æ ¼æ¥è¯´å°±æ˜¯ S Ã— S Ã— B ä¸ª bounding box predictorã€‚


#### 2.2.3 $Pr(Class_i|Object) \times Pr(Object) \times IOU^{truth}_{pred} = Pr(Class_i) \times IOU^{truth}_{pred}$
1. class æ˜¯ä»€ä¹ˆï¼Ÿ
   1. è¿™é‡Œçš„ **class** æŒ‡çš„æ˜¯ï¼š**ç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸­çš„â€œè¯­ä¹‰ç±»åˆ«â€**
   2. å¦‚æžœæ•°æ®é›†æœ‰ **C ä¸ªç±»åˆ«**ï¼Œé‚£ä¹ˆï¼š
      **æ¯ä¸ª grid cell ä¼šè¾“å‡º**ï¼š
      \[
      Pr(Class_1|Object), \dots, Pr(Class_C|Object)
      \]
      å³ï¼š**cell ä¼šè®¡ç®—å‡º C ä¸­æ¯ä¸ªç±»åˆ« class i çš„æ¡ä»¶æ¦‚çŽ‡**
2. ä¸ºä»€ä¹ˆæ˜¯æ¡ä»¶æ¦‚çŽ‡ï¼Ÿ
   1. ä½œè€…æ˜Žç¡®è¯´çš„æ˜¯ï¼š**Pr(Class_i | Object)**è€Œä¸æ˜¯**Pr(Class_i)**ã€‚åŽŸå› æ˜¯ï¼š**YOLO æŠŠâ€œæœ‰æ²¡æœ‰ç‰©ä½“â€å’Œâ€œç‰©ä½“æ˜¯ä»€ä¹ˆç±»åˆ«â€è¿™ä¸¤ä»¶äº‹æ‹†å¼€äº†**ã€‚
   2. æ¢å¥è¯è¯´ï¼šè¿™ä¸ªæ¦‚çŽ‡å›žç­”çš„ä¸æ˜¯ï¼šâ€œ**è¿™ä¸ªåŒºåŸŸæ˜¯æŸä¸€ç±»çš„æ¦‚çŽ‡**â€ï¼Œè€Œæ˜¯ï¼šâ€œ**å¦‚æžœè¿™é‡Œç¡®å®žæœ‰ä¸€ä¸ªç‰©ä½“ï¼Œå®ƒæ˜¯ Class_i çš„æ¦‚çŽ‡**â€
3. classæ˜¯grid cellçº§çš„ï¼Œä¸æ˜¯boxçº§çš„
   1. box predictor ä¸è´Ÿè´£â€œè¿™æ˜¯çŒ«è¿˜æ˜¯ç‹—â€
   1. box predictor åªè´Ÿè´£ï¼šâ€œæˆ‘æ˜¯ä¸æ˜¯ä¸€ä¸ªå¥½æ¡†â€
4. `Pr(Class_i | Object)` æ˜¯æŒ‡ï¼š**åœ¨å½“å‰ grid cell ç¡®å®žå­˜åœ¨ä¸€ä¸ªç”±å®ƒè´Ÿè´£çš„ç‰©ä½“çš„å‰æä¸‹ï¼Œè¯¥ç‰©ä½“å±žäºŽç¬¬ i ç±»çš„æ¦‚çŽ‡ã€‚**

**æ€»ç»“ï¼š**

$$\boxed{\text{Pr(Class i|Object)}} \times \boxed{\text{Pr(Object)} Ã— \text{IOU}^{\text{truth}}_{\text{pred}}} = \text{Pr(Class i)} Ã— \text{IOU}^{\text{truth}}_{\text{pred}}$$

grid cellè´Ÿè´£ï¼š$\boxed{\text{Pr(\text{Class i|Object})}}$ï¼Œå¦‚æžœè¿™é‡Œæœ‰ä¸€ä¸ªç‰©ä½“ï¼Œé‚£ä¹ˆå®ƒå±žäºŽç±»åˆ«Class içš„æ¦‚çŽ‡
bounding boxè´Ÿè´£ï¼š$\boxed{\text{Pr(Object)} \times \text{IOU}^{\text{truth}}_{\text{pred}}}$ï¼Œè¿™é‡Œæœ‰æ²¡æœ‰ç‰©ä½“ï¼Ÿæœ‰ç‰©ä½“çš„è¯ï¼Œæˆ‘æ¡†å¾—å‡†ä¸å‡†ï¼Ÿ
> which gives us class-specific confidence scores for each box. These scores encode both the probability of that class appearing in the box and how well the predicted box fits the **object**(æŒ‡çš„å°±æ˜¯cellå¯¹åº”çš„GTæ¡†).
> ç”±æ­¤å¾—åˆ°æ¯ä¸ªè¾¹ç•Œæ¡†çš„ç±»åˆ«ç‰¹å®šç½®ä¿¡åº¦åˆ†æ•°ã€‚è¿™äº›åˆ†æ•°æ—¢åæ˜ äº†è¯¥ç±»åˆ«å‡ºçŽ°åœ¨æ¡†å†…çš„æ¦‚çŽ‡ï¼Œä¹Ÿä½“çŽ°äº†é¢„æµ‹æ¡†ä¸Ž**ç‰©ä½“**çš„åŒ¹é…ç¨‹åº¦ã€‚

### 2.3 Model 
> Our system models detection as a regression problem. It divides the image into an S Ã— S grid and for each grid cell predicts B bounding boxes, confidence for those boxes, and C class probabilities. These predictions are encoded as an S Ã— S Ã— (B âˆ— 5 + C) tensor.
> æ¨¡åž‹æž¶æž„ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿå°†ç›®æ ‡æ£€æµ‹å»ºæ¨¡ä¸ºä¸€ä¸ªå›žå½’é—®é¢˜ã€‚è¯¥æ–¹æ³•å°†å›¾åƒåˆ’åˆ†ä¸ºSÃ—Sçš„ç½‘æ ¼å•å…ƒï¼Œæ¯ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹Bä¸ªè¾¹ç•Œæ¡†ã€å¯¹åº”æ¡†çš„ç½®ä¿¡åº¦ä»¥åŠ**Cä¸ªç±»åˆ«æ¦‚çŽ‡**ã€‚è¿™äº›**é¢„æµ‹ç»“æžœè¢«ç¼–ç ä¸ºä¸€ä¸ªSÃ—SÃ—(Bâˆ—5 + C)ç»´çš„å¼ é‡**ã€‚
![alt text](image-1.png)

### 2.4 $1 \times 1$ reduction layer
> Our network has 24 convolutional layers followed by 2 fully connected layers. Instead of the inception modules used by GoogLeNet, we **simply use 1 Ã— 1 reduction layers followed by 3 Ã— 3 convolutional layers**, similar to Lin et al [22]. The full network is shown in Figure 3
![alt text](image.png)
1. è¿™é‡Œçš„$1 \times 1$ reduction layerä¹Ÿæ˜¯å·ç§¯å±‚ï¼Œæ˜¯ç”¨æ¥é™ä½Žç»´åº¦çš„ï¼Œä½†æ˜¯ä¸æ˜¯spatial downsamplingï¼ˆå€ŸåŠ©strideï¼‰ï¼Œè€Œæ˜¯channel-wise reductionï¼ˆé™é€šé“æ•°ï¼‰
2. ä¸ºä»€ä¹ˆä¸è¦spatial downsamplingï¼Ÿ
   1. YOLO v1 çš„ backbone éœ€è¦ï¼š**å°½é‡ä¿æŒç©ºé—´åˆ†è¾¨çŽ‡**ã€‚å› ä¸ºåŽé¢è¦åš **grid-based detection**
   2. å¦‚æžœéšä¾¿ç”¨ stride=2ï¼šgrid ä¼šå˜ç²—ï¼Œå°ç›®æ ‡ç›´æŽ¥æ²¡äº†
3. **æ€è€ƒï¼Œé‚£ä¸ºä»€ä¹ˆMaxpoolé‡Œé¢ä»ç„¶ä¿ç•™äº†stride=2åŽ‹ç¼©HÃ—Wç©ºé—´å‘¢ï¼Ÿ**

## III. Train

### 3.1 ä¸€äº›è®­ç»ƒç»†èŠ‚
> Detection often requires fine-grained visual information so we increase the input resolution of the network from 224 Ã— 224 to 448 Ã— 448

> Our final layer predicts both class probabilities and bounding box coordinates. 
> W, H: è¦é™¤ä»¥å›¾ç‰‡çš„å®½åº¦å’Œé«˜åº¦åšå½’ä¸€åŒ–ï¼Œä½¿å…¶å€¼è½åœ¨[0,1]ã€‚
> x, y: å°†å…¶å‚æ•°åŒ–ä¸ºç‰¹å®šç½‘æ ¼å•å…ƒä½ç½®çš„åç§»é‡ï¼Œä½¿å…¶å€¼è½åœ¨[0,1]ã€‚

### 3.2 ä¼˜åŒ–ç›®æ ‡ä¸ŽLosså‡½æ•°
#### 3.2.1 Confidence Loss
> We optimize for sum-squared error in the output of our model. We use sum-squared error because it is easy to optimize, however it does not perfectly align with our goal of maximizing average precision. **It weights localization error equally with classification error which may not be ideal**. Also, in every image many grid cells do not contain any object. This pushes the â€œconfidenceâ€ scores of those cells towards zero, often overpowering the gradient from cells that do contain objects. This can lead to model instability, causing training to diverge early on.
> æˆ‘ä»¬é’ˆå¯¹æ¨¡åž‹è¾“å‡ºçš„è¯¯å·®å¹³æ–¹å’Œè¿›è¡Œä¼˜åŒ–ã€‚é€‰æ‹©è¯¯å·®å¹³æ–¹å’Œä½œä¸ºä¼˜åŒ–ç›®æ ‡æ˜¯å› ä¸ºå…¶æ˜“äºŽå¤„ç†ï¼Œä½†è¿™ä¸€æŒ‡æ ‡ä¸Žæˆ‘ä»¬çš„æ ¸å¿ƒç›®æ ‡â€”â€”æœ€å¤§åŒ–å¹³å‡ç²¾åº¦ï¼ˆaverage precisionï¼‰å¹¶æœªå®Œå…¨å¥‘åˆã€‚è¯¥ä¼˜åŒ–æ–¹å¼å°†å®šä½è¯¯å·®ä¸Žåˆ†ç±»è¯¯å·®ç½®äºŽåŒç­‰æƒé‡ï¼Œè¿™å¯èƒ½å¹¶éžæœ€ä¼˜æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œæ¯å¹…å›¾åƒä¸­å¤§é‡ç½‘æ ¼å•å…ƒå¹¶ä¸åŒ…å«ä»»ä½•ç›®æ ‡ç‰©ä½“ï¼Œè¿™ä¼šå¯¼è‡´è¿™äº›å•å…ƒçš„"ç½®ä¿¡åº¦"åˆ†æ•°è¢«åŽ‹åˆ¶è‡³æŽ¥è¿‘é›¶å€¼ï¼Œå…¶æ¢¯åº¦å¾€å¾€åŽ‹å€’æ€§è¦†ç›–äº†å«ç‰©ä½“å•å…ƒçš„æ¢¯åº¦ä¿¡å·ã€‚æ­¤ç§æƒ…å†µå¯èƒ½å¼•å‘æ¨¡åž‹ä¸ç¨³å®šï¼Œå¯¼è‡´è®­ç»ƒè¿‡ç¨‹åœ¨æ—©æœŸé˜¶æ®µå°±å‡ºçŽ°å‘æ•£çŽ°è±¡ã€‚

è¿™é‡Œä¸å¾—ä¸æåŠä¸€ä¸‹Confidence Losså‡½æ•°çš„è®¡ç®—ä¸Žå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„æµç¨‹ï¼š

1. $\text{Confidence Loss} = \sum{(c_{\text{pred}}-c_{\text{gt}})^2}$ï¼Œå…¶ä¸­ï¼š
2. $c_{\text{pred}}$ï¼šæ˜¯ç½‘ç»œå‰å‘ä¼ æ’­è¾“å‡ºçš„æŸä¸€ä¸ª bounding box predictor å¯¹â€œè¿™ä¸ª box çš„ç½®ä¿¡åº¦â€çš„é¢„æµ‹å€¼ã€‚
   1. ä¹Ÿå°±æ˜¯è®ºæ–‡ä¸­è¯´çš„ï¼š
  \[
  \boxed{\text{Pr(Object)} \times IOU^{\text{truth}}_{\text{pred}}}
  \]
   2. å›¾ç‰‡ä¸­çš„æ¯ä¸€ä¸ª grid cellï¼Œæ¯ä¸ª grid cell ä¸­çš„æ¯ä¸€ä¸ª bounding box predictorï¼Œéƒ½ä¼šæœ‰ä¸€ä¸ªè‡ªå·±çš„$c_{\text{pred}}$åˆ†æ•°ï¼Œ**ä½†æ˜¯ä¸€å¼ å›¾ç‰‡ä¸­å¯èƒ½åªæœ‰å‡ ä¸ªgrid cellæœ‰GTå¯¹åº”ï¼Œä¹Ÿå°±æ˜¯è¯´å¯èƒ½ä¸€å¼ å›¾ç‰‡ä¸­åªæœ‰å‡ ä¸ªbounding box predictorçš„$c_{\text{pred}}$åˆ†æ•°ä¸ä¸º0ï¼Œå…¶ä½™éƒ½ç­‰äºŽ0** 
3. $c_{\text{gt}}$ï¼šæ˜¯è®­ç»ƒæ—¶äººä¸ºæž„é€ çš„â€œè¿™ä¸ª box predictor åº”è¯¥é¢„æµ‹çš„æ­£ç¡®ç½®ä¿¡åº¦â€ã€‚å®ƒä¸æ˜¯ç½‘ç»œç®—å‡ºæ¥çš„ï¼Œè€Œæ˜¯ï¼š
   1. ç”± **GT æ¡† + IOU è§„åˆ™ + è´£ä»»åˆ†é…è§„åˆ™**å†³å®šçš„
   2. å½“å‰ grid cell æ²¡æœ‰è¢«åˆ†é… GTï¼Œé‚£çŽ©å®Œäº†ï¼Œå…¨ä½“bounding box predictorçš„$c_{\text{gt}}$éƒ½ä¸º0
   3. å½“å‰ grid cell æœ‰ä¸€ä¸ª GT boxï¼š
      1. è®¡ç®—å‡ºè¯¥ cell å†…çš„æ‰€æœ‰ B ä¸ª bounding box **ä¸Ž GT çš„ IOU**
      2. æ‰¾åˆ°$IOU$æœ€å¤§çš„é‚£ä¸ª bounding box
      3. è®¾å®šï¼š
      * è¯¥ predictorï¼š
        \[
        c_{\text{gt}} = IOU^{\text{pred box}}_{\text{GT box}}
        \]
      * å…¶ä½™ predictorï¼š
        \[
        c_{\text{gt}} = 0
        \]

å› ä¸ºç©ºç™½bounding boxå¤ªå¤šäº†ï¼Œæ‰€ä»¥å®ƒä»¬çš„confidenceä¸‹é™å¯¹äºŽLosså€¼çš„é™ä½Žæ˜¯éžå¸¸æ˜Žæ˜¾çš„ï¼Œå¯¼è‡´çœŸæ­£çš„ç›®æ ‡ box åœ¨ æ¢¯åº¦åˆæˆä¸­ å‘æŒ¥çš„ä½œç”¨ä¸æ˜Žæ˜¾ï¼Œä¹Ÿå°±æ˜¯è¯´æ‰€å³ä¾¿æ¨¡åž‹æ²¡æœ‰å¾ˆå¥½åœ°æé«˜ç›®æ ‡ box çš„ confidenceï¼Œåªè¦å®ƒæˆåŠŸåœ°æŠŠå¤§é‡ no-object box çš„ confidence åŽ‹ä½Žï¼Œæ€» loss ä»ç„¶å¯ä»¥æŒç»­ä¸‹é™ã€‚
> ä¹‹å‰è¯¯ä»¥ä¸º \(x,y,w,h\) æ˜¯ç›´æŽ¥è¢«ä¼˜åŒ–çš„è‡ªå˜é‡ï¼Œä½†å®žé™…ä¸ŠçœŸæ­£è¢«ä¼˜åŒ–çš„æ˜¯å…±äº«çš„å·ç§¯æ ¸å’Œå…¨è¿žæŽ¥å±‚å‚æ•°ï¼›\(x,y,w,h,c\) åªæ˜¯è¿™äº›å‚æ•°åœ¨ä¸åŒ grid cell å’Œ predictor ä¸Šçš„è¾“å‡ºã€‚ç”±äºŽ no-object box æ•°é‡å·¨å¤§ï¼Œå®ƒä»¬åœ¨ confidence loss ä¸Šäº§ç”Ÿçš„å¤§é‡æ¢¯åº¦ä¼šå…±åŒä½œç”¨äºŽåŒä¸€å¥—ç½‘ç»œå‚æ•°ï¼Œä»Žè€Œä¸»å¯¼å‚æ•°æ›´æ–°æ–¹å‘ï¼Œä½¿å¾—ç½‘ç»œæ›´å€¾å‘äºŽåŽ‹ä½Žæ•´ä½“ confidenceï¼Œè€Œä¸æ˜¯ä¼˜å…ˆæå‡ object box çš„ confidenceã€‚


#### 3.2.2 ä¸¤ä¸ªæƒé‡
> To remedy this, we increase the loss from bounding box coordinate predictions and decrease the loss from confidence predictions for boxes that donâ€™t contain objects. We use two parameters, $Î»_{coord}$ and $Î»_{noobj}$ to accomplish this. We set $Î»_{coord}$ = 5 and $Î»_{noobj}$ = .5.
> å¯¹äºŽä¸åŒ…å«ç‰©ä½“çš„é¢„æµ‹æ¡†ï¼Œå¢žåŠ å…¶è¾¹ç•Œæ¡†åæ ‡é¢„æµ‹çš„æŸå¤±æƒé‡ï¼ŒåŒæ—¶é™ä½Žconfidenceé¢„æµ‹çš„æŸå¤±æƒé‡

#### 3.2.3 Losså‡½æ•°çš„ä¼˜åŒ–
> Our error metric should reflect that small deviations in large boxes matter less than in small boxes.To partially address this we predict the square root of the bounding box width and height instead of the width and height directly.

å› ä¸º$y=\sqrt{w} \rightarrow dy = \frac{1}{2\sqrt{w}}dw$ï¼Œå½“$w$æ¯”è¾ƒå¤§æ—¶ï¼Œ$\Delta w$å¯¹$y$é€ æˆçš„å½±å“å°äºŽåŒç­‰ç¨‹åº¦çš„$\Delta w$ä¸Žå°$w$

#### 3.2.4 bounding boxçš„è´£ä»»åˆ†å·¥
> We assign one predictor to be â€œresponsibleâ€ for predicting an object based on which prediction has the highest current IOU with the ground truth. This leads to specialization between the bounding box predictors. Each predictor gets better at predicting certain sizes, aspect ratios, or classes of object, improving overall recall
> æˆ‘ä»¬æŒ‡å®šä¸€ä¸ªé¢„æµ‹å™¨ä½œä¸º"ä¸»é¢„æµ‹å™¨"æ¥é¢„æµ‹ç›®æ ‡ç‰©ä½“ï¼Œå…¶é€‰æ‹©æ ‡å‡†æ˜¯è¯¥é¢„æµ‹å™¨å½“å‰ä¸ŽçœŸå®žæ ‡æ³¨æ¡†çš„äº¤å¹¶æ¯”(IOU)æœ€é«˜ã€‚è¿™ç§æœºåˆ¶ä¿ƒä½¿ä¸åŒè¾¹ç•Œæ¡†é¢„æµ‹å™¨å½¢æˆä¸“ä¸šåŒ–åˆ†å·¥ï¼šæ¯ä¸ªé¢„æµ‹å™¨ä¼šé€æ¸æ“…é•¿é¢„æµ‹ç‰¹å®šå°ºå¯¸ã€å®½é«˜æ¯”æˆ–ç±»åˆ«çš„ç‰©ä½“ï¼Œä»Žè€Œæ•´ä½“æå‡å¬å›žçŽ‡ã€‚

#### 3.2.5 å®Œæ•´çš„Losså‡½æ•°
loss function:

$\lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} \left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right]$

$+ \lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} \left[ (\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2 \right]$

$+ \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} (C_i - \hat{C}_i)^2$

$+ \lambda_{\text{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{noobj}} (C_i - \hat{C}_i)^2$

$+ \sum_{i=0}^{S^2} \mathbb{1}_{i}^{\text{obj}} \sum_{c \in \text{classes}} \left[p_i(c) - \hat{p}_i(c)\right]^2$

> where $\mathbb{1}_{i}^{\text{obj}}$ denotes if object appears in cell $i$ and $\mathbb{1}_{ij}^{\text{obj}}$ denotes that the $j$th bounding box predictor in cell $i$ is â€œresponsibleâ€ for that prediction.



1. $\hat{x_i}, \hat{y_i}, \hat{w_i}, \hat{h_i}$: cell i çš„ GT Box çš„çœŸå®žä½ç½®å‚æ•°ï¼ˆå½“ç„¶ï¼Œä¼šç»è¿‡ç›¸å¯¹æ¢ç®—ï¼‰
   > ä¾‹å¦‚ï¼Œè¾“å…¥ä¸º$448\times 448$çš„å›¾ç‰‡ï¼Œå½“$S=7$æ—¶ï¼Œæ¯ä¸ªgrid cellçš„å°ºå¯¸éƒ½æ˜¯$64\times64$ï¼Œå¦‚æžœè¯´æœ‰ä¸€ä¸ª GT box çš„ç›®æ ‡ä¸­å¿ƒçš„åƒç´ åæ ‡æ˜¯$(160,200)$ï¼Œå¹¶ä¸”$w=80, h=120$
   > **Step1: è®¡ç®— GT box å±žäºŽå“ªä¸€ä¸ª grid cellï¼š**$i_x=\lfloor160/64\rfloor=2, i_y = \lfloor200/64\rfloor=3$
   > **Step2: è®¡ç®—$x_i, y_i$ï¼š**
   > $\hat{x_i}=(160-2\times64)/64=0.5$
   > $\hat{y_i}=(200-3\times64)/64=0.125$
   > **Step3: è®¡ç®—$w_i, h_i$ï¼š**
   > $\hat{w_i}=80/448\approx0.18$
   > $\hat{h_i}=120/448\approx0.27$
2. $x_i, y_i, w_i, h_i$ï¼šcell i å†… IOU æœ€å¤§çš„ predictor é¢„æµ‹çš„ GT Box çš„ä½ç½®å‚æ•°
3. $\hat{C_i}$ï¼š**å¦‚æžœ bounding box predictor è´Ÿè´£è¯¥ GT Box**ï¼Œ$\hat{C_i} = \text{IOU}^{\text{pred}}_{\text{GT}}$ï¼›**å¦‚æžœ bounding box predictor ä¸è´Ÿè´£è¯¥ GT æˆ–è€…è¯¥ cell is non-object**ï¼Œ$\hat{C_i} = 0$ 
4. $C_i$ï¼šè´Ÿè´£è¯¥ GT çš„ bounding box predictor: $C_i = \text{Pr}(\text{object}) \times \text{IOU}^{\text{pred}}_{\text{GT}}$ï¼ˆå…¶ä½™ B-1 ä¸ª bounding box predictor çš„ $C_i=0$ï¼Œå› ä¸º$\text{Pr(object)=0}$?ï¼‰
5. $\hat{p_i}$ï¼š**ç‹¬çƒ­å‘é‡**ï¼Œè¡¨ç¤º cell i çš„è¿™ä¸ª GT box çš„ç±»åˆ«ï¼Œæ¯”å¦‚ï¼š
   > å¦‚æžœè¯¥ cell ä¸­çš„ç›®æ ‡ç±»åˆ«æ˜¯ â€œdogâ€ï¼š
   > | class | \(\hat{p}_i(c)\) |
   > | ----- | -------------- |
   > | dog   | 1              |
   > | cat   | 0              |
   > | car   | 0              |
   > | ...   | 0              |
   >
   > é‚£ä¹ˆï¼š$\hat{p_i} = [1,0,0,\cdots, 0]$
6. $p_i$ï¼šå½“å‰ cell é¢„æµ‹å‡ºçš„**ç±»åˆ«æ¦‚çŽ‡å‘é‡**ï¼Œä¾‹å¦‚ï¼š
   > $p_i=[0.6,0.3,0.002,\cdots, 0.000001]$    
7. **Losså‡½æ•°å„é¡¹è§£æžï¼š**
   - $\lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} \left[ (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right]$
    å›¾ç‰‡ä¸­çš„æ‰€æœ‰**å…·æœ‰obj**çš„ grid cell ä¸­**è´Ÿè´£è¯¥ GT box çš„ä½ç½®**æŸå¤±
   - $\lambda_{\text{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} \left[ (\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2 \right]$
    å›¾ç‰‡ä¸­çš„æ‰€æœ‰**å…·æœ‰obj**çš„ grid cell ä¸­**è´Ÿè´£è¯¥ GT box çš„å½¢çŠ¶**æŸå¤±
   - $\sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{obj}} (C_i - \hat{C}_i)^2$
    å›¾ç‰‡ä¸­çš„æ‰€æœ‰**å…·æœ‰obj**çš„ grid cell ä¸­**è´Ÿè´£è¯¥ GT box çš„confidence**æŸå¤±ï¼š**æˆ‘è¿™ä¸ªæ¡†æ¡†çš„å‡†å—**ï¼Ÿ
   - $\lambda_{\text{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{1}_{ij}^{\text{noobj}} (C_i - \hat{C}_i)^2$
    è¿™é‡Œçš„$\hat{C_{i}}=0$ï¼Œ**å› ä¸ºè¿™é‡Œæ˜¯èƒŒæ™¯ï¼Œæ ¹æœ¬å°±æ²¡æœ‰ GT boxï¼Œç”šè‡³ä¸å­˜åœ¨æ¡†å¾—å‡†ä¸å‡†çš„é—®é¢˜ï¼Œåªè¦ä½ é¢„æµ‹äº†éžé›¶ confidenceï¼Œå°±è¦è¢«æƒ©ç½š**
   - $\sum_{i=0}^{S^2} \mathbb{1}_{i}^{\text{obj}} \sum_{c \in \text{classes}} \left[p_i(c) - \hat{p}_i(c)\right]^2$
    å…·æœ‰ obj çš„ grid çš„ç±»åˆ«é¢„æµ‹æŸå¤±ã€‚

## IV. Inference
### 4.1 inferenceæ—¶ï¼ŒçœŸçš„ä¼šå‡ºçŽ°å¤šä¸ªgrid cellåŒæ—¶å®šä½ä¸€ä¸ª large object çš„æƒ…å†µå—ï¼Ÿï¼ˆQuesï¼‰
> The grid design enforces spatial diversity in the bounding box predictions. Often it is clear which grid cell an object falls in to and the network only predicts one box for each object. However, some large objects or objects near the border of multiple cells can be well localized by multiple cells. Non-maximal suppression can be used to fix these multiple detections. 
> ç½‘æ ¼è®¾è®¡å¼ºåˆ¶å®žçŽ°äº†è¾¹ç•Œæ¡†é¢„æµ‹çš„ç©ºé—´å¤šæ ·æ€§ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œç‰©ä½“è½å…¥å“ªä¸ªç½‘æ ¼å•å…ƒæ˜¯æ˜Žç¡®çš„ï¼Œç½‘ç»œä»…ä¼šä¸ºæ¯ä¸ªç‰©ä½“é¢„æµ‹ä¸€ä¸ªè¾¹ç•Œæ¡†ã€‚**ç„¶è€Œï¼ŒæŸäº›å¤§åž‹ç‰©ä½“æˆ–ä½äºŽå¤šä¸ªç½‘æ ¼å•å…ƒè¾¹ç¼˜çš„ç‰©ä½“å¯èƒ½è¢«å¤šä¸ªå•å…ƒç²¾ç¡®å®šä½ã€‚æ­¤æ—¶å¯é‡‡ç”¨éžæžå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰æ¥æ¶ˆé™¤è¿™äº›é‡å¤æ£€æµ‹ã€‚**

**æˆ‘çš„åé©³é€»è¾‘ï¼š**
> æˆ‘ä»¬è¯•æƒ³ï¼Œåœ¨è®­ç»ƒé˜¶æ®µï¼Œå¯¹äºŽå¤§ç‰©ä½“ï¼Œåªä¼šæœ‰ä¸€ä¸ªgrid cellæ¥è´Ÿè´£ï¼Œè¿™ä¸ªgrid cellå‘¨å›´çš„grid cellçš„å„ä¸ªbounding box predictorå¹¶ä¸ä¼šè¿›è¡Œé¢„æµ‹ï¼Œç›¸åï¼Œå®ƒä»¬ä¼šè¢«è¿«ä½¿è¾“å‡ºæ›´åŠ å°çš„confidenceï¼Œå› ä¸ºå¤§ç‰©ä½“çš„ä¸­å¿ƒä¸åœ¨å®ƒä»¬é‚£é‡Œï¼Œå®ƒä»¬ä¼šè®¤ä¸ºå®ƒä»¬å¤„äºŽèƒŒæ™¯ä¹‹ä¸­ã€‚é‚£ä¹ˆåœ¨ç½‘ç»œä¸­ï¼Œå‚æ•°çš„è¿­ä»£å°±ä¸ä¼šä½¿å¾—è¿™äº›grid cellè¾“å‡ºå¤§ç‰©ä½“çš„ä¿¡æ¯ã€‚é‚£ä¹ˆï¼Œåœ¨æŽ¨ç†é˜¶æ®µï¼Œä¸ºä»€ä¹ˆåˆå­˜åœ¨ç€è¿‡çš„grid cellé¢„æµ‹åŒä¸€ä¸ªå¤§ç‰©ä½“çš„çŽ°è±¡å‘¢ï¼Ÿ

**GPTçš„è§£é‡Šï¼š**
ä½ çŽ°åœ¨çš„æŽ¨ç†éšå«äº†è¿™æ ·ä¸€ä¸ªå‰æï¼š
> **â€œä¸€ä¸ª grid cell åªæœ‰åœ¨è®­ç»ƒä¸­è¢«æ ‡æ³¨ä¸º responsibleï¼Œå®ƒæ‰å¯èƒ½åœ¨æŽ¨ç†ä¸­å­¦ä¼šé¢„æµ‹è¯¥ç‰©ä½“ã€‚â€**

âš ï¸ è¿™ä¸ªå‰æåœ¨ **å…±äº«å‚æ•° + å›žå½’ä»»åŠ¡** ä¸­æ˜¯ **ä¸æˆç«‹çš„**ã€‚

ä¸‹é¢æ˜¯å…³é”®åŽŸå› ã€‚
**YOLO çš„ box å›žå½’ä¸æ˜¯â€œcell-specific å­¦ä¹ â€ï¼Œè€Œæ˜¯â€œæ¨¡å¼å­¦ä¹ â€**

- 1ï¸âƒ£ é¢„æµ‹ box çš„ä¸æ˜¯ cellï¼Œè€Œæ˜¯å…±äº«ç½‘ç»œå‚æ•°
  > æ‰€æœ‰ cell çš„è¾“å‡ºï¼š
  > \[
  > (x,y,w,h,c)_{i,j} = f_\theta(\text{feature at cell } i)
  > \]
  > å…±äº«**åŒä¸€å¥—å‚æ•° \(\theta\)**ï¼Œåœ¨ä¸åŒç©ºé—´ä½ç½®è¢«é‡å¤ä½¿ç”¨ï¼ˆå·ç§¯ï¼‰
  > 
  > è¿™æ„å‘³ç€ï¼š**åªè¦æŸä¸ªè§†è§‰æ¨¡å¼åœ¨å¤šä¸ª cell å‡ºçŽ°è¿‡ï¼Œé‚£äº› cell çš„è¾“å‡ºå°±å¯èƒ½äº§ç”Ÿâ€œç›¸ä¼¼çš„é¢„æµ‹è¡Œä¸ºâ€**

- 2ï¸âƒ£ å¤§ç‰©ä½“ â‰  åªåœ¨ä¸€ä¸ª cell å‡ºçŽ°
  > è™½ç„¶ supervision åªåœ¨ä¸€ä¸ª cellï¼šä½† **å¤§ç‰©ä½“çš„è§†è§‰æ¨¡å¼**ï¼ˆè¾¹ç¼˜ã€çº¹ç†ã€è¯­ä¹‰ï¼‰å‡ºçŽ°åœ¨å¤šä¸ª cell çš„ feature map ä¸­
  > æ¢å¥è¯è¯´ï¼š
  > **è®­ç»ƒæ—¶ï¼š**â€œä½ è´Ÿè´£ä¸è´Ÿè´£è¿™ä¸ª GTâ€æ˜¯ cell-level çš„ã€‚
  > **ä½†ç½‘ç»œå­¦åˆ°çš„æ˜¯ï¼š**â€œå½“æˆ‘çœ‹åˆ°è¿™ç§ feature æ¨¡å¼æ—¶ï¼Œæˆ‘åº”è¯¥è¾“å‡ºä¸€ä¸ªå¤§æ¡†â€ã€‚

### 4.2 Non-maximal suppression(NMS)
detection é¢†åŸŸçš„**ç»å…¸åŽå¤„ç†ç®—æ³•**ã€‚
**ä¸€å¥è¯å®šä¹‰ï¼š**
> **NMS ç”¨æ¥ï¼š** åœ¨å¤šä¸ªâ€œé«˜åº¦é‡åˆã€è¯­ä¹‰ç›¸åŒâ€çš„é¢„æµ‹æ¡†ä¸­ï¼Œåªä¿ç•™æœ€å¯ä¿¡çš„é‚£ä¸ªï¼Œå…¶ä½™å…¨éƒ¨åˆ æŽ‰

**æ ‡å‡† NMS ç®—æ³•æ­¥éª¤ï¼ˆYOLO v1 é£Žæ ¼ï¼‰**

æˆ‘ä»¬å‡è®¾å·²ç»ç®—å‡ºäº†ï¼š

\[
\text{score} = \Pr(\text{Class}_i) \times \text{IOU}
\]
1. Step 0ï¸âƒ£ï¼šæŒ‰ç±»åˆ«åˆ†ç»„ï¼ˆé€šå¸¸ï¼‰
  å¯¹æ¯ä¸ªç±»åˆ« **å•ç‹¬åš NMS**ï¼ˆYOLO v1 åŽŸè®ºæ–‡å°±æ˜¯è¿™æ ·ç†è§£çš„ï¼‰

2. Step 1ï¸âƒ£ï¼šæŒ‰ score æŽ’åº
  æŠŠè¯¥ç±»åˆ«ä¸‹æ‰€æœ‰ boxï¼šæŒ‰ score ä»Žå¤§åˆ°å°æŽ’åº

3. Step 2ï¸âƒ£ï¼šé€‰å½“å‰æœ€å¤§æ¡†
  å– score æœ€å¤§çš„ boxï¼Œ**åŠ å…¥æœ€ç»ˆç»“æžœé›†åˆ**

4. Step 3ï¸âƒ£ï¼šæŠ‘åˆ¶é‡å æ¡†
  å¯¹å‰©ä½™ boxï¼šè®¡ç®—å®ƒä»¬ä¸Ž**â€œå½“å‰æœ€å¤§æ¡†â€çš„ IOU**
  å¦‚æžœï¼š
  \[
  \text{IOU} > \text{threshold} \quad (\text{å¦‚ } 0.5)
  \]
   **åˆ é™¤è¿™ä¸ª box**
5. Step 4ï¸âƒ£ï¼šé‡å¤
  å¯¹å‰©ä½™ boxï¼Œå›žåˆ° Step 2ï¼Œç›´åˆ°æ²¡æœ‰ box ä¸ºæ­¢

**ä¸€ä¸ªç›´è§‚å°ä¾‹å­**

| box | score | IOU with best |
| --- | ----- | ------------- |
| A   | 0.92  | â€”             |
| B   | 0.85  | 0.78 âŒ        |
| C   | 0.60  | 0.12 âœ…        |

* ä¿ç•™ A
* åˆ é™¤ Bï¼ˆé‡å å¤ªå¤§ï¼‰
* ä¿ç•™ C


## V. Experiments

### 5.1 ä»€ä¹ˆå«åšï¼šâ€œWe also train YOLO using VGG-16.â€ï¼Ÿ
- **æ ¸å¿ƒæ€æƒ³ï¼š**
> **â€œå¦‚æžœæˆ‘ç”¨ä¸€ä¸ªæ›´å¼ºçš„åˆ†ç±»ç½‘ç»œæ¥åšç‰¹å¾æå–ï¼Œä¼šä¸ä¼šæ£€æµ‹æ›´å‡†ï¼Ÿâ€**
- å…·ä½“ç»“æž„ä¸Šå‘ç”Ÿäº†ä»€ä¹ˆï¼ˆéžå¸¸é‡è¦ï¼‰
  åŽŸ YOLOï¼š
  ```
  [Custom Conv Stack] â†’ [FC Detection Head]
  ```
  YOLO + VGG-16ï¼š
  ```
  [VGG-16 Conv Layers] â†’ [FC Detection Head]
  ```

- YOLOåªç”¨ VGG-16 çš„ **å·ç§¯éƒ¨åˆ†**
  * VGG-16 çš„ç»“æž„æ˜¯ï¼š

  ```
  Conv â†’ Conv â†’ Pool â†’ ...
  ...
  Conv â†’ Conv â†’ Conv â†’ Pool
  FC â†’ FC â†’ FC
  ```
  åªä¿ç•™å·ç§¯å±‚éƒ¨åˆ†ï¼Œ**ä¸¢æŽ‰ VGG-16 åŽŸæœ¬ç”¨äºŽåˆ†ç±»çš„ FC å±‚**

- æŠŠ YOLO çš„ detection head æŽ¥åœ¨åŽé¢ã€‚YOLO çš„ headï¼š
  * å›žå½’ box
  * é¢„æµ‹ confidence
  * é¢„æµ‹ class

  ä¹Ÿå°±æ˜¯è¯´ï¼š**VGG-16 ä¸å†åšåˆ†ç±»ï¼Œå®ƒåªè´Ÿè´£â€œæç‰¹å¾â€**

- accuaracyæå‡ä½†æ˜¯å˜å¾—éžå¸¸æ…¢ï¼ŒåŽŸå› æ˜¯VGGå·ç§¯å±‚å¤šï¼Œå‚æ•°é‡å·¨å¤§

### 5.2 VOC 2007 Error Analysis
Each prediction is either correct or it is classified based on the type of error:
- Correct: correct class and IOU > 0.5
- Localization: correct class, 0.1 < IOU < 0.5
- Similar: class is similar, IOU > 0.1
- Other: class is wrong, IOU > 0.1
- Background: IOU < 0.1 for any object

YOLO vs Fast R-CNN:
![alt text](image-2.png)
- YOLO struggles to localize objects correctly. 
- Fast R-CNN makes much fewer localization errors but far more background errors. 

### 5.3 Combination with Fast R-CNN
> For every bounding box that R-CNN predicts we check to see if YOLO predicts a similar box. If it does, we give that prediction a boost based on the probability predicted by YOLO and the overlap between the two boxes.

> mAP increases by 3.2% to 75.0%

> We also tried combining the top Fast R-CNN model with several other versions of Fast R-CNN. Those ensembles produced small increases in mAP between .3 and .6%, see Table 2 for details

### 5.4 Artwork
> YOLO has good performance on VOC 2007 and its AP degrades less than other methods when applied to artwork. Like DPM, YOLO models the size and shape of objects, as well as relationships between objects and where objects commonly appear. Artwork and natural images are very different on a pixel level but they are similar in terms of the size and shape of objects, thus YOLO can still predict good bounding boxes and detections
> YOLOåœ¨VOC 2007æ•°æ®é›†ä¸Šè¡¨çŽ°å‡ºè‰²ï¼Œä¸”åœ¨åº”ç”¨äºŽè‰ºæœ¯ä½œå“æ—¶å…¶å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰ä¸‹é™å¹…åº¦å°äºŽå…¶ä»–æ–¹æ³•ã€‚ä¸ŽDPMç±»ä¼¼ï¼Œ**YOLOèƒ½å¤Ÿå»ºæ¨¡ç‰©ä½“çš„å°ºå¯¸ã€å½¢çŠ¶ã€ç‰©ä½“é—´çš„ç©ºé—´å…³ç³»ä»¥åŠå¸¸è§å‡ºçŽ°ä½ç½®**ã€‚è™½ç„¶è‰ºæœ¯ä½œå“ä¸Žè‡ªç„¶å›¾åƒåœ¨**åƒç´ å±‚é¢å·®å¼‚æ˜¾è‘—**ï¼Œä½†äºŒè€…åœ¨ç‰©ä½“å°ºå¯¸å’Œå½¢çŠ¶ç‰¹å¾ä¸Šå…·æœ‰ç›¸ä¼¼æ€§ï¼Œå› æ­¤YOLOä»èƒ½é¢„æµ‹å‡ºä¼˜è´¨çš„è¾¹ç•Œæ¡†å’Œæ£€æµ‹ç»“æžœã€‚

### 5.5 Real-time system
> YOLO is a fast, accurate object detector, making it ideal for computer vision applications. We connect YOLO to a webcam and verify that it maintains real-time performance including the time to fetch images from the camera and display the detections.
> YOLOæ˜¯ä¸€ç§å¿«é€Ÿã€ç²¾å‡†çš„ç›®æ ‡æ£€æµ‹ç®—æ³•ï¼Œç‰¹åˆ«é€‚åˆè®¡ç®—æœºè§†è§‰åº”ç”¨åœºæ™¯ã€‚æˆ‘ä»¬å°†YOLOä¸Žç½‘ç»œæ‘„åƒå¤´è¿žæŽ¥ï¼ŒéªŒè¯å…¶ä»Žæ‘„åƒå¤´èŽ·å–å›¾åƒåˆ°æ˜¾ç¤ºæ£€æµ‹ç»“æžœçš„å…¨æµç¨‹ä»èƒ½ä¿æŒå®žæ—¶æ€§èƒ½ã€‚


## VI. YOLO v1ä¼˜åŠ¿ä¸Žæ½œåœ¨é—®é¢˜
### 6.1 ä¼˜åŠ¿
1. ç«¯åˆ°ç«¯ã€å•é˜¶æ®µæ£€æµ‹ã€å•ç½‘ç»œã€‚ï¼ˆä¸éœ€è¦slide windows, æ²¡æœ‰å¤šé˜¶æ®µpipelineï¼Œä¸éœ€è¦å¯¹å„ä¸ªæ¨¡å—è¿›è¡Œå•ç‹¬è®­ç»ƒï¼‰
2. å¿«ï¼Œreal-time
3. backgroundé”™è¯¯å°‘
   >YOLO reasons globally about the imageâ€¦
   
   æ¯ä¸ªé¢„æµ‹åŸºäºŽå›¾åƒä¸Šä¸‹æ–‡ï¼Œæ›´å°‘å°†èƒŒæ™¯è¯¯åˆ¤ä¸ºç›®æ ‡
4. æ³›åŒ–èƒ½åŠ›å¼ºï¼šåœ¨æµ‹è¯•artworkè¿™ç§ä¸Žç»å…¸æ•°æ®é›†ä¸åŒçš„å›¾åƒæ—¶ï¼Œä¹Ÿèƒ½ä¿æŒå¾ˆé«˜çš„accuarcy

### 6.2 æ½œåœ¨é—®é¢˜
1. å®šä½ç²¾åº¦é—®é¢˜ã€‚åˆšåˆšæåˆ°çš„ï¼Œä¸€ä¸ªobjectä»…ä»…ç”±ä¸€ä¸ª grid cell è´Ÿè´£ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œå°¤å…¶æ˜¯å¯¹äºŽ Large object (ä¸€ä¸ªgrid cellè´Ÿè´£ä¸€æ•´ä¸ªå¤§ç‰©ä½“) å’Œ å°è€Œå¯†çš„ç‰©ä½“ï¼ˆå¤šä¸ªç‰©ä½“çš„ä¸­å¿ƒå‡ºçŽ°åœ¨ä¸€ä¸ªgrid cellï¼‰
2. downsample å±‚ä¼šä¸ä¼šåŽ‹ç¼©å›¾åƒç‰¹å¾ï¼Œé™ä½Žé¢„æµ‹æ•ˆæžœï¼Ÿ 
    > Our model also uses relatively coarse features for predicting bounding boxes since our architecture has multiple downsampling layers from the input image
3. our loss function treats **errors the same in small bounding boxes versus large bounding boxes**


