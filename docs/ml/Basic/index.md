---
hide:
  - toc
---

<div class="section-hero ml-hero">
  <h1>🧠 机器学习</h1>
  <p>从神经网络基础到 Transformer，系统学习深度学习核心知识</p>
  <div class="section-stats">
    <span class="stat-item">📚 5 篇笔记</span>
    <span class="stat-item">🎯 由浅入深</span>
  </div>
</div>

<div class="card-grid">

<a class="note-card pink" href="ch1_Full_Connected_NN/ch1_神经网络与深度学习基础/">
  <span class="card-icon">🔗</span>
  <div class="card-title">Chapter 1 · 全连接神经网络</div>
  <p class="card-desc">神经网络与深度学习基础，前向传播与反向传播算法</p>
</a>

<a class="note-card purple" href="ch2_Optimization/ch2_2_Optimization/">
  <span class="card-icon">⚡</span>
  <div class="card-title">Chapter 2 · 优化</div>
  <p class="card-desc">梯度下降、学习率调度、正则化等优化技巧</p>
</a>

<a class="note-card blue" href="ch3_CNN/ch3_CNN/">
  <span class="card-icon">🖼️</span>
  <div class="card-title">Chapter 3 · CNN</div>
  <p class="card-desc">卷积神经网络：卷积层、池化层与经典架构</p>
</a>

<a class="note-card teal" href="ch4_Self_Attention/ch4_self_attention基础/">
  <span class="card-icon">👁️</span>
  <div class="card-title">Chapter 4 · Self-Attention</div>
  <p class="card-desc">自注意力机制原理与多头注意力</p>
</a>

<a class="note-card orange" href="ch5_Transformer/ch5_transformer基础/">
  <span class="card-icon">🤖</span>
  <div class="card-title">Chapter 5 · Transformer</div>
  <p class="card-desc">Transformer 架构详解：编码器与解码器</p>
</a>

</div>
